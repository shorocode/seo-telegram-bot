import logging
from typing import Dict, List, Tuple, Optional
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    Filters,
    CallbackContext,
    Dispatcher
)
from transformers import pipeline, AutoModelForSeq2SeqLM, AutoTokenizer
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import re
import json
import os
from pathlib import Path
from dataclasses import dataclass
import hashlib
from functools import lru_cache

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
@dataclass
class Config:
    BOT_TOKEN: str = "YOUR_BOT_TOKEN"
    MODEL_CACHE_DIR: str = "model_cache"
    USER_DATA_DIR: str = "user_data"
    MAX_CONTENT_LENGTH: int = 5000
    KEYWORD_SUGGESTIONS: int = 10
    CONTENT_TYPES: Dict[str, str] = {
        "article": "Ù…Ù‚Ø§Ù„Ù‡",
        "product": "Ù…Ø­ØµÙˆÙ„",
        "landing": "ØµÙØ­Ù‡ ÙØ±ÙˆØ¯",
        "blog": "Ø¨Ù„Ø§Ú¯ Ù¾Ø³Øª"
    }

class SEOAnalytics:
    """Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø¦Ùˆ"""
    
    @staticmethod
    def calculate_readability(text: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙ† (Flesch-Kincaid Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)"""
        words = text.split()
        sentences = re.split(r'[.!?]', text)
        words_count = len(words)
        sentences_count = len([s for s in sentences if s.strip()])
        
        if words_count == 0 or sentences_count == 0:
            return 0
            
        avg_words_per_sentence = words_count / sentences_count
        syllables_count = sum([SEOAnalytics.count_syllables(word) for word in words])
        avg_syllables_per_word = syllables_count / words_count
        
        readability = 206.835 - (1.015 * avg_words_per_sentence) - (84.6 * avg_syllables_per_word)
        return max(0, min(100, readability))

    @staticmethod
    def count_syllables(word: str) -> int:
        """Ø´Ù…Ø§Ø±Ø´ Ù‡Ø¬Ø§Ù‡Ø§ÛŒ Ú©Ù„Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ"""
        vowels = ['Ø§', 'Ø¢', 'ÛŒ', 'Ùˆ', 'Ù‡', 'Ù†', 'Ù…', 'Ø¡']
        return sum(1 for char in word if char in vowels)

    @staticmethod
    def keyword_density(text: str, keywords: List[str]) -> Dict[str, float]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ±Ø§Ú©Ù… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        word_count = len(text.split())
        density = {}
        
        for keyword in keywords:
            keyword = keyword.strip()
            if not keyword:
                continue
                
            count = text.lower().count(keyword.lower())
            density[keyword] = (count / word_count) * 100 if word_count > 0 else 0
            
        return density

class ModelManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†"""
    
    def __init__(self, config: Config):
        self.config = config
        self._setup_dirs()
        self.models = {}
        
    def _setup_dirs(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…"""
        Path(self.config.MODEL_CACHE_DIR).mkdir(exist_ok=True)
        Path(self.config.USER_DATA_DIR).mkdir(exist_ok=True)
    
    def load_models(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ú©Ø´ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§ÙØ¸Ù‡"""
        try:
            self.models = {
                "keyword": self._load_keyword_model(),
                "content": self._load_content_model(),
                "similarity": self._load_similarity_model(),
                "optimization": self._load_optimization_model()
            }
            logger.info("ØªÙ…Ø§Ù…ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {e}")
            raise

    @lru_cache(maxsize=1)
    def _load_keyword_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        return pipeline(
            "text2text-generation",
            model="google/flan-t5-small",
            device="cpu",
            cache_dir=self.config.MODEL_CACHE_DIR
        )

    @lru_cache(maxsize=1)
    def _load_content_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        return pipeline(
            "text-generation",
            model="facebook/bart-base",
            device="cpu",
            cache_dir=self.config.MODEL_CACHE_DIR
        )

    @lru_cache(maxsize=1)
    def _load_similarity_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ†"""
        return SentenceTransformer(
            'paraphrase-multilingual-MiniLM-L12-v2',
            device='cpu',
            cache_folder=self.config.MODEL_CACHE_DIR
        )

    @lru_cache(maxsize=1)
    def _load_optimization_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†"""
        model_name = "t5-small"
        tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=self.config.MODEL_CACHE_DIR)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=self.config.MODEL_CACHE_DIR)
        return (model, tokenizer)

class OfflineSEOBot:
    """Ø±Ø¨Ø§Øª Ø³Ø¦Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ†"""
    
    def __init__(self, config: Config):
        self.config = config
        self.updater = Updater(config.BOT_TOKEN, use_context=True)
        self.dp = self.updater.dispatcher
        self.model_manager = ModelManager(config)
        self.model_manager.load_models()
        self.user_states: Dict[int, Dict] = {}
        self.setup_handlers()
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ú©Ø´ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        self._load_user_data()

    def _load_user_data(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² ÙØ§ÛŒÙ„"""
        try:
            data_file = Path(self.config.USER_DATA_DIR) / "user_data.json"
            if data_file.exists():
                with open(data_file, 'r', encoding='utf-8') as f:
                    self.user_states = json.load(f)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {e}")

    def _save_user_data(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¯Ø± ÙØ§ÛŒÙ„"""
        try:
            data_file = Path(self.config.USER_DATA_DIR) / "user_data.json"
            with open(data_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_states, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {e}")

    def setup_handlers(self):
        """ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÙˆØ±Ø§Øª Ø±Ø¨Ø§Øª"""
        handlers = [
            CommandHandler("start", self.start),
            CommandHandler("help", self.show_help),
            CallbackQueryHandler(self.handle_button),
            MessageHandler(Filters.text & ~Filters.command, self.handle_message),
            
            # Ø¯Ø³ØªÙˆØ±Ø§Øª Ø³Ø¦Ùˆ
            CommandHandler("keywords", self.suggest_keywords),
            CommandHandler("content", self.generate_content),
            CommandHandler("optimize", self.optimize_text),
            CommandHandler("compare", self.compare_texts),
            CommandHandler("analyze", self.analyze_seo),
            CommandHandler("history", self.show_history)
        ]
        
        for handler in handlers:
            self.dp.add_handler(handler)

    # --- ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
    def start(self, update: Update, context: CallbackContext):
        """Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ"""
        user = update.effective_user
        logger.info(f"Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø´Ø±ÙˆØ¹ Ú©Ø±Ø¯: {user.id} - {user.full_name}")
        
        keyboard = [
            [InlineKeyboardButton("ğŸ”‘ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ", callback_data='keywords')],
            [InlineKeyboardButton("ğŸ“ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§", callback_data='content')],
            [InlineKeyboardButton("âœï¸ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†", callback_data='optimize')],
            [InlineKeyboardButton("ğŸ†š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ†", callback_data='compare')],
            [InlineKeyboardButton("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ", callback_data='analyze')],
            [InlineKeyboardButton("â„¹ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§", callback_data='help')]
        ]
        
        update.message.reply_text(
            f"ğŸ¤– Ø³Ù„Ø§Ù… {user.first_name}!\nØ¨Ù‡ Ø±Ø¨Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø³Ø¦Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ† Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\n\n"
            "Ø§Ù…Ú©Ø§Ù†Ø§Øª Ø¯Ø± Ø¯Ø³ØªØ±Ø³:",
            reply_markup=InlineKeyboardMarkup(keyboard)
        )

    def show_help(self, update: Update, context: CallbackContext):
        """Ù†Ù…Ø§ÛŒØ´ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±Ø¨Ø§Øª"""
        help_text = """
ğŸ“š Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø±Ø¨Ø§Øª Ø³Ø¦Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ†:

ğŸ” <b>Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ</b>
/keywords [Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ] - Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·

ğŸ“ <b>ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§</b>
/content [Ù†ÙˆØ¹] [Ù…ÙˆØ¶ÙˆØ¹] - ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø¦Ùˆ Ø´Ø¯Ù‡
Ø§Ù†ÙˆØ§Ø¹ Ù…Ø­ØªÙˆØ§: article, product, landing, blog

âœï¸ <b>Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†</b>
/optimize [Ù…ØªÙ†] - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ

ğŸ†š <b>Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ†</b>
/compare [Ù…ØªÙ†1]\n[Ù…ØªÙ†2] - Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ù…ØªÙ†

ğŸ“Š <b>ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ</b>
/analyze [Ù…ØªÙ†] - ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø³Ø¦Ùˆ Ù…ØªÙ†

ğŸ“œ <b>ØªØ§Ø±ÛŒØ®Ú†Ù‡</b>
/history - Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
"""
        update.message.reply_text(help_text, parse_mode="HTML")

    def handle_button(self, update: Update, context: CallbackContext):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§"""
        query = update.callback_query
        query.answer()
        user_id = query.from_user.id
        
        if query.data == 'keywords':
            self.user_states[user_id] = {'state': 'awaiting_keyword'}
            query.edit_message_text("ğŸ” Ù„Ø·ÙØ§ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
        
        elif query.data == 'content':
            self.show_content_menu(query)
        
        elif query.data == 'optimize':
            self.user_states[user_id] = {'state': 'awaiting_optimize'}
            query.edit_message_text("âœï¸ Ù„Ø·ÙØ§ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:")
        
        elif query.data == 'compare':
            self.user_states[user_id] = {'state': 'awaiting_compare'}
            query.edit_message_text("ğŸ†š Ù„Ø·ÙØ§ Ø¯Ùˆ Ù…ØªÙ† Ø±Ø§ Ø¨Ø§ Ø®Ø· Ø¬Ø¯ÛŒØ¯ (Enter) Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯:")
        
        elif query.data == 'analyze':
            self.user_states[user_id] = {'state': 'awaiting_analyze'}
            query.edit_message_text("ğŸ“Š Ù„Ø·ÙØ§ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø´ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:")
        
        elif query.data == 'help':
            self.show_help(update)
        
        elif query.data.startswith('gen_'):
            content_type = query.data[4:]
            self.user_states[user_id] = {
                'state': 'awaiting_content_topic',
                'content_type': content_type
            }
            query.edit_message_text(f"ğŸ“ Ù„Ø·ÙØ§ Ù…ÙˆØ¶ÙˆØ¹ {self.config.CONTENT_TYPES.get(content_type, '')} Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
        
        elif query.data == 'back':
            self.start(update, context)

    # --- ØªÙˆØ§Ø¨Ø¹ Ø³Ø¦Ùˆ Ø¢ÙÙ„Ø§ÛŒÙ† ---
    def suggest_keywords(self, update: Update, context: CallbackContext):
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ (Ø¨Ø¯ÙˆÙ† API)"""
        keyword = ' '.join(context.args) if context.args else None
        
        if not keyword:
            self.user_states[update.effective_user.id] = {'state': 'awaiting_keyword'}
            update.message.reply_text("ğŸ” Ù„Ø·ÙØ§ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
            return
        
        try:
            prompt = (
                f"Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ {self.config.KEYWORD_SUGGESTIONS} Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ '{keyword}' Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ "
                "Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª Ø¹Ø¯Ø¯ÛŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡:"
            )
            
            result = self.model_manager.models["keyword"](
                prompt,
                max_length=150,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.7
            )
            
            keywords = result[0]['generated_text'].strip()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            self._add_to_history(
                update.effective_user.id,
                "keywords",
                {"input": keyword, "output": keywords}
            )
            
            update.message.reply_text(
                f"ğŸ” Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ '{keyword}':\n\n{keywords}\n\n"
                "ğŸ’¡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            )
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§ Ù…Ø¬Ø¯Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    def generate_content(self, update: Update, context: CallbackContext):
        """ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø¦Ùˆ Ø´Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† API)"""
        args = context.args
        user_id = update.effective_user.id
        
        if len(args) < 2 and user_id not in self.user_states:
            self.show_content_menu(update)
            return
        
        if user_id in self.user_states and self.user_states[user_id]['state'] == 'awaiting_content_topic':
            content_type = self.user_states[user_id]['content_type']
            topic = ' '.join(args) if args else None
            
            if not topic:
                update.message.reply_text("Ù„Ø·ÙØ§ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
                return
        else:
            if len(args) < 2:
                update.message.reply_text("âš ï¸ ÙØ±Ù…Øª Ø¯Ø³ØªÙˆØ±: /content [Ù†ÙˆØ¹] [Ù…ÙˆØ¶ÙˆØ¹]")
                return
                
            content_type, topic = args[0], ' '.join(args[1:])
        
        try:
            # ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§
            if content_type == "article":
                prompt = (
                    f"Ù…Ù‚Ø§Ù„Ù‡ Ø§ÛŒ 300 Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ '{topic}' Ø¨Ø§ Ø±Ø¹Ø§ÛŒØª Ø§ØµÙˆÙ„ Ø³Ø¦Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ:\n"
                    "â€¢ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ (H2, H3)\n"
                    "â€¢ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ùâ€ŒÙ‡Ø§ÛŒ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø®ÙˆØ§Ù†Ø§\n"
                    "â€¢ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·\n"
                    "â€¢ Ø³Ø§Ø®ØªØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ù…ÙˆØªÙˆØ±Ù‡Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ"
                )
            elif content_type == "product":
                prompt = (
                    f"ØªÙˆØ¶ÛŒØ­ Ù…Ø­ØµÙˆÙ„ Ø¨Ø±Ø§ÛŒ '{topic}' Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³Ø¦Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ:\n"
                    "â€¢ Ù…Ø¹Ø±ÙÛŒ Ù…Ø­ØµÙˆÙ„\n"
                    "â€¢ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ\n"
                    "â€¢ Ù…Ø²Ø§ÛŒØ§\n"
                    "â€¢ Ø¯Ø¹ÙˆØª Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… (CTA)"
                )
            else:
                prompt = f"Ù…ØªÙ† Ø³Ø¦Ùˆ Ø´Ø¯Ù‡ Ø¯Ø±Ø¨Ø§Ø±Ù‡ '{topic}' Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ:"
            
            result = self.model_manager.models["content"](
                prompt,
                max_length=500,
                num_return_sequences=1,
                do_sample=True,
                temperature=0.7,
                top_p=0.9
            )
            
            content = result[0]['generated_text'].strip()
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            self._add_to_history(
                user_id,
                "content",
                {"type": content_type, "topic": topic, "output": content}
            )
            
            update.message.reply_text(
                f"ğŸ“ Ù…Ø­ØªÙˆØ§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ ({self.config.CONTENT_TYPES.get(content_type, '')}):\n\n"
                f"{content}\n\n"
                "ğŸ’¡ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø§ÛŒÙ† Ù…ØªÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø¯Ø³ØªÙˆØ± /analyze Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            )
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±
            if user_id in self.user_states:
                del self.user_states[user_id]
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§ Ù…Ø¬Ø¯Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    def optimize_text(self, update: Update, context: CallbackContext):
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ"""
        text = ' '.join(context.args) if context.args else None
        user_id = update.effective_user.id
        
        if not text:
            if user_id not in self.user_states:
                self.user_states[user_id] = {'state': 'awaiting_optimize'}
                update.message.reply_text("âœï¸ Ù„Ø·ÙØ§ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:")
            return
        
        try:
            model, tokenizer = self.model_manager.models["optimization"]
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
            input_text = f"Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ: {text}"
            inputs = tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)
            
            # ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡
            outputs = model.generate(
                inputs,
                max_length=512,
                num_beams=5,
                early_stopping=True,
                temperature=0.7
            )
            
            optimized_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            self._add_to_history(
                user_id,
                "optimize",
                {"input": text, "output": optimized_text}
            )
            
            update.message.reply_text(
                f"âœï¸ Ù…ØªÙ† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡:\n\n{optimized_text}\n\n"
                "ğŸ’¡ ØªØºÛŒÛŒØ±Ø§Øª Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯Ù‡:\n"
                "- Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø§Ø®ØªØ§Ø± Ù…ØªÙ†\n"
                "- Ø§ÙØ²ÙˆØ¯Ù† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·\n"
                "- Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ"
            )
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±
            if user_id in self.user_states:
                del self.user_states[user_id]
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ† Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§ Ù…Ø¬Ø¯Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    def compare_texts(self, update: Update, context: CallbackContext):
        """Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ù…ØªÙ†"""
        if context.args:
            texts = ' '.join(context.args).split('\n')
        else:
            texts = None
            
        user_id = update.effective_user.id
        
        if not texts or len(texts) < 2:
            if user_id not in self.user_states:
                self.user_states[user_id] = {'state': 'awaiting_compare'}
                update.message.reply_text("ğŸ†š Ù„Ø·ÙØ§ Ø¯Ùˆ Ù…ØªÙ† Ø±Ø§ Ø¯Ø± Ø®Ø·ÙˆØ· Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:")
            return
        
        try:
            # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø´Ú©Ù„Ø§Øª Ø­Ø§ÙØ¸Ù‡
            texts = [text[:self.config.MAX_CONTENT_LENGTH] for text in texts[:2]]
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª
            embeddings = self.model_manager.models["similarity"].encode(texts)
            similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0] * 100
            
            # ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ
            readability = [
                SEOAnalytics.calculate_readability(texts[0]),
                SEOAnalytics.calculate_readability(texts[1])
            ]
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            self._add_to_history(
                user_id,
                "compare",
                {
                    "text1": texts[0],
                    "text2": texts[1],
                    "similarity": similarity,
                    "readability": readability
                }
            )
            
            update.message.reply_text(
                f"ğŸ” Ù†ØªØ§ÛŒØ¬ Ù…Ù‚Ø§ÛŒØ³Ù‡:\n\n"
                f"ğŸ“ Ù…ØªÙ† Ø§ÙˆÙ„ (Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {readability[0]:.1f}/100):\n{texts[0][:100]}...\n\n"
                f"ğŸ“ Ù…ØªÙ† Ø¯ÙˆÙ… (Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {readability[1]:.1f}/100):\n{texts[1][:100]}...\n\n"
                f"ğŸ“Š Ù…ÛŒØ²Ø§Ù† Ø´Ø¨Ø§Ù‡Øª Ù…Ø­ØªÙˆØ§Ù‡Ø§: {similarity:.1f}%\n\n"
                f"ğŸ’¡ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ Ø¨Ù‡ØªØ± Ø§Ø³Øª."
            )
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±
            if user_id in self.user_states:
                del self.user_states[user_id]
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ†: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ† Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§ Ù…Ø¬Ø¯Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    def analyze_seo(self, update: Update, context: CallbackContext):
        """ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø³Ø¦Ùˆ Ù…ØªÙ†"""
        text = ' '.join(context.args) if context.args else None
        user_id = update.effective_user.id
        
        if not text:
            if user_id not in self.user_states:
                self.user_states[user_id] = {'state': 'awaiting_analyze'}
                update.message.reply_text("ğŸ“Š Ù„Ø·ÙØ§ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ ØªØ­Ù„ÛŒÙ„ Ø´ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:")
            return
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ
            keyword_prompt = f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ 5 Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ Ø§Ø² Ù…ØªÙ† Ø²ÛŒØ± Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ:\n{text[:500]}"
            keywords = self.model_manager.models["keyword"](
                keyword_prompt,
                max_length=100,
                num_return_sequences=1
            )[0]['generated_text'].split(', ')
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø³Ø¦Ùˆ
            readability = SEOAnalytics.calculate_readability(text)
            density = SEOAnalytics.keyword_density(text, keywords)
            
            # ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ù…ØªÙ†
            structure_prompt = f"ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ù…ØªÙ† Ø²ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø³Ø¦Ùˆ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ:\n{text[:500]}"
            structure_analysis = self.model_manager.models["keyword"](
                structure_prompt,
                max_length=200,
                num_return_sequences=1
            )[0]['generated_text']
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            self._add_to_history(
                user_id,
                "analyze",
                {
                    "text": text,
                    "keywords": keywords,
                    "readability": readability,
                    "density": density,
                    "structure": structure_analysis
                }
            )
            
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø²Ø§Ø±Ø´
            report = (
                f"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ:\n\n"
                f"ğŸ” Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø§ØµÙ„ÛŒ:\n{', '.join(keywords)}\n\n"
                f"ğŸ“ˆ ØªØ±Ø§Ú©Ù… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:\n"
            )
            
            for kw, dens in density.items():
                report += f"- {kw}: {dens:.2f}%\n"
            
            report += (
                f"\nğŸ“– Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {readability:.1f}/100\n"
                f"ğŸ’¡ {self._get_readability_feedback(readability)}\n\n"
                f"ğŸ—ï¸ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø±:\n{structure_analysis}\n\n"
                f"ğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª: {self._get_seo_suggestions(readability, density)}"
            )
            
            update.message.reply_text(report)
            
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±
            if user_id in self.user_states:
                del self.user_states[user_id]
                
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§ Ù…Ø¬Ø¯Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    def show_history(self, update: Update, context: CallbackContext):
        """Ù†Ù…Ø§ÛŒØ´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
        user_id = update.effective_user.id
        history = self._get_user_history(user_id)
        
        if not history:
            update.message.reply_text("ğŸ“œ ØªØ§Ø±ÛŒØ®Ú†Ù‡â€ŒØ§ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return
        
        message = "ğŸ“œ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§:\n\n"
        for i, item in enumerate(history[-5:], 1):  # ÙÙ‚Ø· 5 Ù…ÙˆØ±Ø¯ Ø¢Ø®Ø±
            message += (
                f"{i}. {item['type']} - {item['timestamp']}\n"
                f"   ÙˆØ±ÙˆØ¯ÛŒ: {item['data'].get('input', item['data'].get('text', '...'))[:30]}...\n\n"
            )
        
        update.message.reply_text(message)

    # --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
    def show_content_menu(self, update):
        """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        keyboard = [
            [InlineKeyboardButton("ğŸ“° Ù…Ù‚Ø§Ù„Ù‡", callback_data='gen_article')],
            [InlineKeyboardButton("ğŸ“¦ Ù…Ø­ØµÙˆÙ„", callback_data='gen_product')],
            [InlineKeyboardButton("ğŸ  ØµÙØ­Ù‡ ÙØ±ÙˆØ¯", callback_data='gen_landing')],
            [InlineKeyboardButton("âœï¸ Ø¨Ù„Ø§Ú¯ Ù¾Ø³Øª", callback_data='gen_blog')],
            [InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data='back')]
        ]
        
        if hasattr(update, 'callback_query'):
            update.callback_query.edit_message_text(
                "Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                reply_markup=InlineKeyboardMarkup(keyboard)
        else:
            update.message.reply_text(
                "Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
                reply_markup=InlineKeyboardMarkup(keyboard))

    def handle_message(self, update: Update, context: CallbackContext):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
        user_id = update.effective_user.id
        text = update.message.text
        
        if user_id not in self.user_states:
            self.start(update, context)
            return
        
        state = self.user_states[user_id]['state']
        
        if state == 'awaiting_keyword':
            context.args = [text]
            self.suggest_keywords(update, context)
        
        elif state == 'awaiting_optimize':
            context.args = [text]
            self.optimize_text(update, context)
        
        elif state == 'awaiting_compare':
            context.args = text.split('\n')
            self.compare_texts(update, context)
        
        elif state == 'awaiting_analyze':
            context.args = [text]
            self.analyze_seo(update, context)
        
        elif state == 'awaiting_content_topic':
            context.args = [text]
            self.generate_content(update, context)
        
        # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø­Ø§Ù„Øª Ú©Ø§Ø±Ø¨Ø±
        if user_id in self.user_states:
            del self.user_states[user_id]

    def _add_to_history(self, user_id: int, action_type: str, data: Dict):
        """Ø§ÙØ²ÙˆØ¯Ù† ÙØ¹Ø§Ù„ÛŒØª Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        try:
            history_file = Path(self.config.USER_DATA_DIR) / f"{user_id}_history.json"
            history = []
            
            if history_file.exists():
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            history.append({
                "type": action_type,
                "timestamp": str(datetime.now()),
                "data": data
            })
            
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history[-50:], f, ensure_ascii=False, indent=2)  # ÙÙ‚Ø· 50 Ù…ÙˆØ±Ø¯ Ø¢Ø®Ø±
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")

    def _get_user_history(self, user_id: int) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        try:
            history_file = Path(self.config.USER_DATA_DIR) / f"{user_id}_history.json"
            if history_file.exists():
                with open(history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")
        return []

    def _get_readability_feedback(self, score: float) -> str:
        """Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ"""
        if score > 80:
            return "Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¹Ø§Ù„ÛŒ! Ù…ØªÙ† Ø´Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ú©Ø«Ø± Ù…Ø®Ø§Ø·Ø¨Ø§Ù† Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø§Ø³Øª."
        elif score > 60:
            return "Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø®ÙˆØ¨. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ø®ÛŒ Ø¬Ù…Ù„Ø§Øª Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯."
        elif score > 40:
            return "Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ù…ØªÙˆØ³Ø·. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¬Ù…Ù„Ø§Øª Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ú©Ù†ÛŒØ¯."
        else:
            return "Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¶Ø¹ÛŒÙ. Ù…ØªÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ù†ÙˆÛŒØ³ÛŒ Ø§Ø³Ø§Ø³ÛŒ Ø¯Ø§Ø±Ø¯."

    def _get_seo_suggestions(self, readability: float, density: Dict[str, float]) -> str:
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø¦Ùˆ"""
        suggestions = []
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ
        if readability < 40:
            suggestions.append("Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø¬Ù…Ù„Ø§Øª Ú©ÙˆØªØ§Ù‡â€ŒØªØ± ØªÙ‚Ø³ÛŒÙ… Ú©Ù†ÛŒØ¯.")
        elif readability < 60:
            suggestions.append("Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ùˆ Ø¬Ù…Ù„Ø§Øª Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
        
        # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ø§Ú©Ù… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
        for kw, dens in density.items():
            if dens < 1:
                suggestions.append(f"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ '{kw}' Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯.")
            elif dens > 3:
                suggestions.append(f"Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ '{kw}' Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯.")
        
        return " ".join(suggestions) if suggestions else "Ù…ØªÙ† Ø´Ù…Ø§ Ø§Ø² Ù†Ø¸Ø± Ø³Ø¦Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ø¯."

    def run(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª"""
        self.updater.start_polling()
        logger.info("Ø±Ø¨Ø§Øª Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯...")
        self.updater.idle()

if __name__ == '__main__':
    config = Config()
    bot = OfflineSEOBot(config)
    bot.run()
