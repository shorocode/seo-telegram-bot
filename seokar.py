import json
import logging
import os
import re
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from functools import lru_cache
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
from urllib.parse import urlparse
import hashlib
import numpy as np
import pytz
import requests
from bs4 import BeautifulSoup
from cryptography.fernet import Fernet
from google.cloud import translate_v2 as translate
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import (
    CallbackContext,
    CallbackQueryHandler,
    CommandHandler,
    Dispatcher,
    Filters,
    JobQueue,
    MessageHandler,
    Updater,
)
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline
from concurrent.futures import ThreadPoolExecutor
from cachetools import TTLCache
import backoff
from prometheus_client import start_http_server, Counter, Gauge

# ##################################################
# ## ---------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø³ÛŒØ³ØªÙ… ---------- ##
# ##################################################

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§ÛŒÙ‡ Ù„Ø§Ú¯ÛŒÙ†Ú¯
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Prometheus
REQUEST_COUNTER = Counter('bot_requests_total', 'Total bot requests', ['endpoint'])
ERROR_COUNTER = Counter('bot_errors_total', 'Total bot errors', ['endpoint'])
ACTIVE_USERS_GAUGE = Gauge('bot_active_users', 'Currently active users')
MODEL_LOAD_TIME = Gauge('model_load_time_seconds', 'Time taken to load models', ['model_name'])

# ##################################################
# ## ---------- Ø³Ø§Ø®ØªØ§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ ---------- ##
# ##################################################

@dataclass(frozen=True)
class SubscriptionPlan:
    """Ø·Ø±Ø­ Ø§Ø´ØªØ±Ø§Ú© Ø¨Ø§ ØªÙ…Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§"""
    name: str
    monthly_price: int
    annual_price: int
    features: List[str]
    rate_limit: int
    max_content_length: int
    advanced_analytics: bool
    api_access: bool
    priority_support: bool
    team_members: int
    color_code: str = "#4CAF50"  # Ø±Ù†Ú¯ Ù¾ÛŒØ´â€ŒÙØ±Ø¶

@dataclass
class Config:
    """Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø§ØµÙ„ÛŒ Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶"""
    BOT_TOKEN: str = os.getenv('BOT_TOKEN', '')
    MODEL_CACHE_DIR: str = "model_cache"
    USER_DATA_DIR: str = "user_data"
    BACKUP_DIR: str = "backups"
    MAX_CONTENT_LENGTH: int = 30000
    KEYWORD_SUGGESTIONS: int = 25
    CONTENT_TYPES: Dict[str, str] = field(default_factory=lambda: {
        "article": "Ù…Ù‚Ø§Ù„Ù‡",
        "product": "Ù…Ø­ØµÙˆÙ„",
        "landing": "ØµÙØ­Ù‡ ÙØ±ÙˆØ¯",
        "blog": "Ù¾Ø³Øª ÙˆØ¨Ù„Ø§Ú¯",
        "video": "Ù…Ø­ØªÙˆÛŒ ÙˆÛŒØ¯Ø¦ÙˆÛŒÛŒ",
        "social": "Ù¾Ø³Øª Ø´Ø¨Ú©Ù‡ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ"
    })
    DEFAULT_RATE_LIMIT: int = 15
    ENCRYPTION_KEY: str = os.getenv('ENCRYPTION_KEY', '')
    GOOGLE_API_KEY: Optional[str] = os.getenv('GOOGLE_API_KEY')
    TIMEZONE: str = "Asia/Tehran"
    MAX_CONCURRENT_REQUESTS: int = 10
    REQUEST_TIMEOUT: int = 30
    SENTRY_DSN: Optional[str] = os.getenv('SENTRY_DSN')
    
    SUBSCRIPTION_PLANS: Dict[str, SubscriptionPlan] = field(default_factory=lambda: {
        "free": SubscriptionPlan(
            "Ø±Ø§ÛŒÚ¯Ø§Ù†", 0, 0,
            ["Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ", "ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ù¾Ø§ÛŒÙ‡", "Ûµ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø±ÙˆØ²"],
            5, 2000, False, False, False, 1, "#9E9E9E"
        ),
        "pro": SubscriptionPlan(
            "Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ", 99000, 990000,
            ["ØªÙ…Ø§Ù… Ø§Ù…Ú©Ø§Ù†Ø§Øª Ù¾Ø§ÛŒÙ‡", "ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§", "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡", "ÛµÛ° Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø±ÙˆØ²"],
            50, 10000, True, False, False, 3, "#2196F3"
        ),
        "enterprise": SubscriptionPlan(
            "Ø³Ø§Ø²Ù…Ø§Ù†ÛŒ", 299000, 2990000,
            ["ØªÙ…Ø§Ù… Ø§Ù…Ú©Ø§Ù†Ø§Øª", "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ", "API Ø¯Ø³ØªØ±Ø³ÛŒ", "ØªÛŒÙ… Ûµ Ù†ÙØ±Ù‡", "Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø­Ø¯ÙˆØ¯"],
            1000, 30000, True, True, True, 5, "#FF5722"
        )
    })

# ##################################################
# ## ---------- Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„â€ŒÙ‡Ø§ ---------- ##
# ##################################################

class ModelManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹"""
    
    def __init__(self, config: Config):
        self.config = config
        self._setup_dirs()
        self.models = {}
        self.load_times = {}
        self.executor = ThreadPoolExecutor(max_workers=config.MAX_CONCURRENT_REQUESTS)
        self.model_cache = TTLCache(maxsize=10, ttl=3600)  # Ú©Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ 1 Ø³Ø§Ø¹Øª
        
    def _setup_dirs(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬ÙˆØ²Ù‡Ø§"""
        try:
            os.makedirs(self.config.MODEL_CACHE_DIR, exist_ok=True, mode=0o755)
            os.makedirs(self.config.USER_DATA_DIR, exist_ok=True, mode=0o700)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§: {e}")
            raise

    @backoff.on_exception(backoff.expo, Exception, max_tries=3)
    def load_models(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯"""
        try:
            start_time = time.time()
            
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
            with ThreadPoolExecutor() as executor:
                futures = {
                    executor.submit(self._load_keyword_model): "keyword",
                    executor.submit(self._load_content_model): "content",
                    executor.submit(self._load_similarity_model): "similarity",
                    executor.submit(self._load_optimization_model): "optimization",
                    executor.submit(self._load_translation_model): "translation"
                }
                
                for future in futures:
                    model_name = futures[future]
                    try:
                        self.models[model_name] = future.result()
                    except Exception as e:
                        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ {model_name}: {e}")
                        raise

            logger.info(f"ØªÙ…Ø§Ù…ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± {time.time() - start_time:.2f} Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯")
            return True
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {e}")
            return False

    @lru_cache(maxsize=1)
    def _load_keyword_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ"""
        logger.info("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ...")
        start_time = time.time()
        
        try:
            model = pipeline(
                "text2text-generation",
                model="google/flan-t5-large",
                device="cuda" if torch.cuda.is_available() else "cpu",
                cache_dir=self.config.MODEL_CACHE_DIR
            )
            load_time = time.time() - start_time
            MODEL_LOAD_TIME.labels(model_name="keyword").set(load_time)
            logger.info(f"Ù…Ø¯Ù„ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± {load_time:.2f} Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return model
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {e}")
            raise

    @lru_cache(maxsize=1)
    def _load_content_model(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§"""
        logger.info("Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§...")
        start_time = time.time()
        
        try:
            model = pipeline(
                "text-generation",
                model="facebook/bart-large-cnn",
                device="cuda" if torch.cuda.is_available() else "cpu",
                cache_dir=self.config.MODEL_CACHE_DIR
            )
            load_time = time.time() - start_time
            MODEL_LOAD_TIME.labels(model_name="content").set(load_time)
            logger.info(f"Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø¯Ø± {load_time:.2f} Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return model
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§: {e}")
            raise

    # Ø§Ø¯Ø§Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±...

    def unload_model(self, model_name: str):
        """ØªØ®Ù„ÛŒÙ‡ Ù…Ø¯Ù„ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª ØµØ­ÛŒØ­ Ù…Ù†Ø§Ø¨Ø¹"""
        if model_name in self.models:
            del self.models[model_name]
            if model_name == "keyword":
                self._load_keyword_model.cache_clear()
            elif model_name == "content":
                self._load_content_model.cache_clear()
            logger.info(f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ®Ù„ÛŒÙ‡ Ø´Ø¯")

    async def async_predict(self, model_name: str, input_data: Any):
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª ØµÙ"""
        if model_name not in self.models:
            raise ValueError(f"Ù…Ø¯Ù„ {model_name} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
        
        try:
            future = self.executor.submit(self.models[model_name], input_data)
            return await asyncio.wrap_future(future)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ {model_name}: {e}")
            raise

# ##################################################
# ## ---------- Ø³ÛŒØ³ØªÙ… Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---------- ##
# ##################################################

class SecurityManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ùˆ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª"""
    
    def __init__(self, encryption_key: str):
        if not encryption_key:
            raise ValueError("Ú©Ù„ÛŒØ¯ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
        
        if len(encryption_key) < 32:
            raise ValueError("Ú©Ù„ÛŒØ¯ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ Û³Û² Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨Ø§Ø´Ø¯")
            
        self.cipher = Fernet(Fernet.generate_key())
        self.hmac_key = os.urandom(32)
        self.token_cache = TTLCache(maxsize=1000, ttl=3600)
        
    def encrypt_data(self, data: str) -> str:
        """Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ù¾ÛŒØ§Ù… (HMAC)"""
        if not data:
            raise ValueError("Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
            
        encrypted = self.cipher.encrypt(data.encode())
        hmac = hmac.new(self.hmac_key, encrypted, hashlib.sha256).hexdigest()
        return f"{encrypted.decode()}:{hmac}"

    def decrypt_data(self, encrypted_data: str) -> str:
        """Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ ØµØ­Øª Ù¾ÛŒØ§Ù…"""
        if not encrypted_data:
            raise ValueError("Ø¯Ø§Ø¯Ù‡ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯")
            
        try:
            encrypted, hmac_value = encrypted_data.split(":")
            if not encrypted or not hmac_value:
                raise ValueError("ÙØ±Ù…Øª Ø¯Ø§Ø¯Ù‡ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª")
                
            calculated_hmac = hmac.new(self.hmac_key, encrypted.encode(), hashlib.sha256).hexdigest()
            if not hmac.compare_digest(calculated_hmac, hmac_value):
                raise ValueError("Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚ HMAC - Ø§Ø­ØªÙ…Ø§Ù„ Ø¯Ø³ØªÚ©Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡")
                
            return self.cipher.decrypt(encrypted.encode()).decode()
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±Ù…Ø²Ú¯Ø´Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡: {e}")
            raise

    def generate_token(self, user_id: int, expires_in: int = 3600) -> str:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆÚ©Ù† Ø§Ù…Ù†ÛŒØªÛŒ Ø¨Ø§ Ø²Ù…Ø§Ù† Ø§Ù†Ù‚Ø¶Ø§"""
        token = hashlib.sha256(f"{user_id}{time.time()}{os.urandom(16)}".encode()).hexdigest()
        self.token_cache[token] = {
            "user_id": user_id,
            "expires_at": time.time() + expires_in
        }
        return token

    def validate_token(self, token: str) -> Optional[int]:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ ØªÙˆÚ©Ù† Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        if token in self.token_cache:
            token_data = self.token_cache[token]
            if token_data["expires_at"] > time.time():
                return token_data["user_id"]
        return None

# ##################################################
# ## ---------- Ø³ÛŒØ³ØªÙ… ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ---------- ##
# ##################################################

class SEOAnalytics:
    """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø³Ø¦Ùˆ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡"""
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
        self.readability_cache = TTLCache(maxsize=1000, ttl=3600)
        self.keyword_cache = TTLCache(maxsize=1000, ttl=1800)
        
    @staticmethod
    def preprocess_text(text: str) -> str:
        """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„"""
        if not text:
            return ""
            
        # Ø­Ø°Ù ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        text = re.sub(r'\s+', ' ', text).strip()
        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†ÙˆÛŒØ³Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
        text = text.replace('ÙŠ', 'ÛŒ').replace('Ùƒ', 'Ú©')
        return text

    def calculate_readability(self, text: str, lang: str = 'fa') -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø³Ø·Ø­ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ø§ Ú©Ø´ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬"""
        cache_key = hashlib.md5(text.encode()).hexdigest()
        
        if cache_key in self.readability_cache:
            return self.readability_cache[cache_key]
            
        text = self.preprocess_text(text)
        if not text:
            return 0.0
            
        try:
            if lang == 'fa':
                # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
                words = text.split()
                sentences = [s for s in re.split(r'[.!?ØŸ]+', text) if s.strip()]
                
                if not words or not sentences:
                    return 0.0
                    
                words_count = len(words)
                sentences_count = len(sentences)
                syllables_count = sum(self.count_syllables(word) for word in words)
                
                avg_words = words_count / sentences_count
                avg_syllables = syllables_count / words_count
                
                readability = 206.835 - (1.3 * avg_words) - (60.6 * avg_syllables)
                result = max(0, min(100, readability))
            else:
                # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ø±Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                result = textstat.flesch_reading_ease(text)
                
            self.readability_cache[cache_key] = result
            return result
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ: {e}")
            return 0.0

    def keyword_density(self, text: str, keywords: List[str]) -> Dict[str, float]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ±Ø§Ú©Ù… Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ú©Ø´ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´"""
        if not text or not keywords:
            return {}
            
        cache_key = hashlib.md5((text + ''.join(sorted(keywords))).encode()).hexdigest()
        if cache_key in self.keyword_cache:
            return self.keyword_cache[cache_key]
            
        text = self.preprocess_text(text).lower()
        words = text.split()
        total_words = len(words)
        result = {}
        
        for keyword in keywords:
            keyword = self.preprocess_text(keyword).lower()
            if not keyword:
                continue
                
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† ØµÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
            pattern = re.compile(rf'\b{re.escape(keyword)}\b', re.IGNORECASE)
            count = len(pattern.findall(text))
            density = (count / total_words) * 100 if total_words > 0 else 0
            result[keyword] = round(density, 2)
            
        self.keyword_cache[cache_key] = result
        return result

    def analyze_competition(self, url: str, user_content: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø±Ù‚Ø§Ø¨Øª Ø¨Ø§ ÙˆØ¨Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±"""
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ Ø±Ù‚ÛŒØ¨
            response = requests.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            competitor_content = ' '.join([
                tag.get_text() for tag in soup.find_all(['p', 'h1', 'h2', 'h3'])
            ])
            
            # ØªØ­Ù„ÛŒÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ
            return self.compare_contents(user_content, competitor_content)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø§Ø¨Øª: {e}")
            return {"error": str(e)}

    def compare_contents(self, content1: str, content2: str) -> Dict[str, Any]:
        """Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¯Ùˆ Ù…Ø­ØªÙˆØ§"""
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ù…ØªÙ†ÛŒ
            model = self.model_manager.models.get("similarity")
            if not model:
                raise ValueError("Ù…Ø¯Ù„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ØªÙˆÙ† Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡")
                
            emb1 = model.encode([self.preprocess_text(content1)])
            emb2 = model.encode([self.preprocess_text(content2)])
            similarity = cosine_similarity(emb1, emb2)[0][0]
            
            # ØªØ­Ù„ÛŒÙ„ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
            keywords1 = self.extract_keywords(content1)
            keywords2 = self.extract_keywords(content2)
            
            # ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ
            readability1 = self.calculate_readability(content1)
            readability2 = self.calculate_readability(content2)
            
            return {
                "similarity_score": round(similarity * 100, 2),
                "content1_keywords": keywords1[:10],
                "content2_keywords": keywords2[:10],
                "missing_keywords": list(set(keywords2) - set(keywords1))[:10],
                "content1_readability": readability1,
                "content2_readability": readability2,
                "suggestions": self.generate_suggestions(content1, content2)
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø­ØªÙˆØ§: {e}")
            return {"error": str(e)}


# ##################################################
# ## ------ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù¾ÛŒØ´Ø±ÙØªÙ‡ ------ ##
# ##################################################

class UserProfile:
    """Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø§Ø´ØªØ±Ø§Ú© Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª"""
    
    def __init__(self, user_id: int, config: Config, security_manager: SecurityManager):
        self.user_id = user_id
        self.config = config
        self.security = security_manager
        self.data = {
            "subscription": {
                "plan": "free",
                "start_date": datetime.now(pytz.timezone(config.TIMEZONE)).isoformat(),
                "expiry_date": None,
                "payment_method": None,
                "renewal": False
            },
            "preferences": {
                "language": "fa",
                "content_style": "formal",
                "tone": "professional",
                "notifications": True,
                "dark_mode": False
            },
            "usage": {
                "daily_requests": 0,
                "monthly_requests": 0,
                "total_requests": 0,
                "last_request": None,
                "request_history": []
            },
            "content": {
                "saved_items": [],
                "favorites": [],
                "collections": {}
            },
            "security": {
                "last_login": datetime.now(pytz.timezone(config.TIMEZONE)).isoformat(),
                "login_history": [],
                "two_fa_enabled": False
            }
        }
        self.lock = threading.Lock()
        
    def update_usage(self, request_type: str) -> bool:
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ù…Ø²Ù…Ø§Ù†ÛŒ"""
        with self.lock:
            now = datetime.now(pytz.timezone(self.config.TIMEZONE))
            today = now.date()
            last_date = datetime.fromisoformat(self.data["usage"]["last_request"]).date() if self.data["usage"]["last_request"] else None
            
            # Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ú¯Ø± Ø±ÙˆØ² Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ø´Ø¯
            if last_date is None or last_date != today:
                self.data["usage"]["daily_requests"] = 0
                
            # Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ú¯Ø± Ù…Ø§Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ø´Ø¯
            if last_date is None or last_date.month != today.month:
                self.data["usage"]["monthly_requests"] = 0
                
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø§Ø´ØªØ±Ø§Ú©
            plan = self.config.SUBSCRIPTION_PLANS.get(self.data["subscription"]["plan"])
            if not plan:
                return False
                
            if self.data["usage"]["daily_requests"] >= plan.rate_limit:
                return False
                
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±
            self.data["usage"]["daily_requests"] += 1
            self.data["usage"]["monthly_requests"] += 1
            self.data["usage"]["total_requests"] += 1
            self.data["usage"]["last_request"] = now.isoformat()
            self.data["usage"]["request_history"].append({
                "type": request_type,
                "timestamp": now.isoformat(),
                "status": "completed"
            })
            
            return True

    def can_make_request(self, request_type: str) -> Tuple[bool, str]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ú©Ø§Ù† Ø§Ù†Ø¬Ø§Ù… Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§"""
        plan = self.config.SUBSCRIPTION_PLANS.get(self.data["subscription"]["plan"])
        if not plan:
            return False, "Ø·Ø±Ø­ Ø§Ø´ØªØ±Ø§Ú© Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
            
        if self.data["usage"]["daily_requests"] >= plan.rate_limit:
            reset_time = (datetime.now(pytz.timezone(self.config.TIMEZONE)) + timedelta(days=1)
            reset_str = reset_time.strftime("%H:%M")
            return False, f"Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±ÙˆØ²Ø§Ù†Ù‡. ØªØ§ Ø³Ø§Ø¹Øª {reset_str} ØµØ¨Ø± Ú©Ù†ÛŒØ¯"
            
        return True, ""

    def save_content(self, content_data: Dict) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§"""
        content_id = self.security.hash_data(f"{content_data['title']}{time.time()}")
        
        content_item = {
            "id": content_id,
            "type": content_data.get("type", "article"),
            "title": content_data.get("title", "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"),
            "content": content_data["content"],
            "tags": content_data.get("tags", []),
            "created_at": datetime.now(pytz.timezone(self.config.TIMEZONE)).isoformat(),
            "modified_at": datetime.now(pytz.timezone(self.config.TIMEZONE)).isoformat(),
            "metadata": content_data.get("metadata", {})
        }
        
        with self.lock:
            self.data["content"]["saved_items"].append(content_item)
            
        return content_id

    def get_content(self, content_id: str) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±"""
        with self.lock:
            for item in self.data["content"]["saved_items"]:
                if item["id"] == content_id:
                    return item
        return None

    def upgrade_subscription(self, plan_id: str, payment_method: str, duration: str = "monthly") -> bool:
        """Ø§Ø±ØªÙ‚Ø§Ø¡ Ø§Ø´ØªØ±Ø§Ú© Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øª"""
        if plan_id not in self.config.SUBSCRIPTION_PLANS:
            return False
            
        now = datetime.now(pytz.timezone(self.config.TIMEZONE))
        
        with self.lock:
            self.data["subscription"]["plan"] = plan_id
            self.data["subscription"]["payment_method"] = payment_method
            self.data["subscription"]["start_date"] = now.isoformat()
            
            if duration == "monthly":
                expiry = now + timedelta(days=30)
            else:  # annual
                expiry = now + timedelta(days=365)
                
            self.data["subscription"]["expiry_date"] = expiry.isoformat()
            self.data["subscription"]["renewal"] = True
            
        return True

# ##################################################
# ## ----- Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ Ø§Ø´ØªØ±Ø§Ú© Ù¾ÛŒØ´Ø±ÙØªÙ‡ ----- ##
# ##################################################

class PaymentManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÙ‡Ø§ Ùˆ Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§ Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯Ø±ÙˆØ§Ø²Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª"""
    
    def __init__(self, config: Config):
        self.config = config
        self.plans = config.SUBSCRIPTION_PLANS
        self.payment_providers = {
            "zarinpal": self._init_zarinpal(),
            "idpay": self._init_idpay()
        }
        self.receipts = TTLCache(maxsize=1000, ttl=86400)  # Ú©Ø´ Ø±Ø³ÛŒØ¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ 24 Ø³Ø§Ø¹Øª
        
    def _init_zarinpal(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø±ÙˆØ§Ø²Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„"""
        return {
            "api_key": os.getenv("ZARINPAL_API_KEY"),
            "sandbox": os.getenv("ZARINPAL_SANDBOX", "false").lower() == "true",
            "callback_url": os.getenv("ZARINPAL_CALLBACK_URL")
        }
        
    def _init_idpay(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø±ÙˆØ§Ø²Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢ÛŒØ¯ÛŒ Ù¾ÛŒ"""
        return {
            "api_key": os.getenv("IDPAY_API_KEY"),
            "sandbox": os.getenv("IDPAY_SANDBOX", "false").lower() == "true",
            "callback_url": os.getenv("IDPAY_CALLBACK_URL")
        }

    def initiate_payment(self, user_id: int, plan_id: str, provider: str = "zarinpal") -> Optional[str]:
        """Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù„ÛŒÙ†Ú© Ù¾Ø±Ø¯Ø§Ø®Øª"""
        if provider not in self.payment_providers:
            return None
            
        plan = self.plans.get(plan_id)
        if not plan:
            return None
            
        amount = plan.monthly_price
        description = f"Ø§Ø±ØªÙ‚Ø§Ø¡ Ø¨Ù‡ Ø·Ø±Ø­ {plan.name}"
        
        try:
            if provider == "zarinpal":
                payment_url = self._zarinpal_payment(user_id, amount, description)
            elif provider == "idpay":
                payment_url = self._idpay_payment(user_id, amount, description)
            else:
                return None
                
            return payment_url
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø®Øª: {e}")
            return None

    def verify_payment(self, payment_id: str, provider: str) -> Tuple[bool, Dict]:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù†ØªÛŒØ¬Ù‡"""
        if provider not in self.payment_providers:
            return False, {"error": "Ù¾Ø±ÙˆØ§ÛŒØ¯Ø± Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±"}
            
        try:
            if provider == "zarinpal":
                return self._verify_zarinpal(payment_id)
            elif provider == "idpay":
                return self._verify_idpay(payment_id)
            else:
                return False, {"error": "Ù¾Ø±ÙˆØ§ÛŒØ¯Ø± Ù¾Ø±Ø¯Ø§Ø®Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø±"}
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ£ÛŒÛŒØ¯ Ù¾Ø±Ø¯Ø§Ø®Øª: {e}")
            return False, {"error": str(e)}

    def _zarinpal_payment(self, user_id: int, amount: int, description: str) -> Optional[str]:
        """Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø§Ø² Ø·Ø±ÛŒÙ‚ Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„"""
        # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„ Ø¯Ø§Ø±Ø¯
        payment_url = f"https://zarinpal.com/pg/StartPay/{user_id}_{int(time.time())}"
        self.receipts[payment_url] = {
            "user_id": user_id,
            "amount": amount,
            "description": description,
            "timestamp": time.time()
        }
        return payment_url

    def _verify_zarinpal(self, payment_id: str) -> Tuple[bool, Dict]:
        """Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù¾Ø±Ø¯Ø§Ø®Øª Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„"""
        # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ø²Ø±ÛŒÙ†â€ŒÙ¾Ø§Ù„ Ø¯Ø§Ø±Ø¯
        return True, {
            "success": True,
            "amount": self.receipts.get(payment_id, {}).get("amount", 0),
            "transaction_id": f"zarinpal_{int(time.time())}"
        }

# ##################################################
# ## ----- Ø³ÛŒØ³ØªÙ… Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³ ----- ##
# ##################################################

class AnalyticsManager:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø¢Ù…Ø§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    
    def __init__(self, config: Config):
        self.config = config
        self.report_cache = TTLCache(maxsize=100, ttl=3600)
        
    def generate_seo_report(self, analysis_data: Dict, user_id: int = None) -> bytes:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ PDF Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ"""
        cache_key = hashlib.md5(json.dumps(analysis_data).encode()).hexdigest()
        
        if cache_key in self.report_cache:
            return self.report_cache[cache_key]
            
        try:
            buffer = io.BytesIO()
            c = canvas.Canvas(buffer, pagesize=letter)
            
            # Ù‡Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´
            self._draw_header(c, "Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ", user_id)
            
            # Ù…Ø­ØªÙˆØ§ÛŒ Ú¯Ø²Ø§Ø±Ø´
            y_position = 650
            for section, content in analysis_data.items():
                y_position = self._draw_section(c, section, content, y_position)
                if y_position < 100:
                    c.showPage()
                    self._draw_header(c, "Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ (Ø§Ø¯Ø§Ù…Ù‡)", user_id)
                    y_position = 650
                    
            # ÙÙˆØªØ± Ú¯Ø²Ø§Ø±Ø´
            self._draw_footer(c)
            
            c.save()
            pdf_data = buffer.getvalue()
            self.report_cache[cache_key] = pdf_data
            return pdf_data
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´: {e}")
            raise

    def _draw_header(self, c, title: str, user_id: int = None):
        """Ø±Ø³Ù… Ù‡Ø¯Ø± Ú¯Ø²Ø§Ø±Ø´"""
        c.setFont("Helvetica-Bold", 16)
        c.drawString(100, 750, title)
        
        c.setFont("Helvetica", 10)
        c.drawString(100, 730, f"ØªØ§Ø±ÛŒØ® ØªÙˆÙ„ÛŒØ¯: {datetime.now(pytz.timezone(self.config.TIMEZONE)).strftime('%Y-%m-%d %H:%M')}")
        
        if user_id:
            c.drawString(100, 710, f"Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ø±Ø¨Ø±: {user_id}")
            
        c.line(100, 700, 500, 700)

    def _draw_section(self, c, title: str, content: Any, y_pos: int) -> int:
        """Ø±Ø³Ù… ÛŒÚ© Ø¨Ø®Ø´ Ø§Ø² Ú¯Ø²Ø§Ø±Ø´"""
        c.setFont("Helvetica-Bold", 14)
        c.drawString(100, y_pos, title)
        y_pos -= 25
        
        c.setFont("Helvetica", 12)
        if isinstance(content, dict):
            for key, value in content.items():
                c.drawString(120, y_pos, f"{key}: {value}")
                y_pos -= 20
        elif isinstance(content, list):
            for item in content:
                c.drawString(120, y_pos, f"- {item}")
                y_pos -= 20
        else:
            c.drawString(120, y_pos, str(content))
            y_pos -= 20
            
        return y_pos - 10  # ÙØ§ØµÙ„Ù‡ Ù‚Ø¨Ù„ Ø§Ø² Ø¨Ø®Ø´ Ø¨Ø¹Ø¯ÛŒ

    def _draw_footer(self, c):
        """Ø±Ø³Ù… ÙÙˆØªØ± Ú¯Ø²Ø§Ø±Ø´"""
        c.setFont("Helvetica", 8)
        c.drawString(100, 30, f"ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ø±Ø¨Ø§Øª Ø³Ø¦ÙˆÚ©Ø§Ø± - {datetime.now(pytz.timezone(self.config.TIMEZONE)).strftime('%Y-%m-%d')}")

# ##################################################
# ## ----- Ø³ÛŒØ³ØªÙ… ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯ÙˆÚ¯Ù„ ----- ##
# ##################################################

class GoogleIntegration:
    """Ù…Ø¯ÛŒØ±ÛŒØª ÛŒÚ©Ù¾Ø§Ø±Ú†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ú¯ÙˆÚ¯Ù„"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.translate_client = translate.Client(api_key) if api_key else None
        self.session = requests.Session()
        self.session.headers.update({
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        })
        
    def translate_text(self, text: str, target_lang: str = 'fa') -> str:
        """ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Google Cloud Translation"""
        if not self.translate_client:
            raise ValueError("Ú©Ù„ÛŒØ¯ API ØªØ±Ø¬Ù…Ù‡ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            
        try:
            result = self.translate_client.translate(
                text,
                target_language=target_lang,
                format_='text'
            )
            return result['translatedText']
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ†: {e}")
            raise

    def get_search_console_data(self, site_url: str, start_date: str, end_date: str) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ú† Ú©Ù†Ø³ÙˆÙ„ Ú¯ÙˆÚ¯Ù„"""
        try:
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ÙˆØ§Ù‚Ø¹ÛŒ
            params = {
                "siteUrl": site_url,
                "startDate": start_date,
                "endDate": end_date,
                "dimensions": ["query", "page"],
                "rowLimit": 100
            }
            
            # Ø¯Ø± ÛŒÚ© Ø³ÛŒØ³ØªÙ… ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø§ÛŒÙ†Ø¬Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ API Ú¯ÙˆÚ¯Ù„ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            return {
                "clicks": 1200,
                "impressions": 8500,
                "ctr": 0.14,
                "position": 8.3,
                "top_keywords": [
                    {"keyword": "Ø¢Ù…ÙˆØ²Ø´ Ø³Ø¦Ùˆ", "clicks": 320},
                    {"keyword": "Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§ÛŒØª", "clicks": 210},
                    {"keyword": "Ø±Ø¨Ø§Øª Ø³Ø¦Ùˆ", "clicks": 150}
                ],
                "top_pages": [
                    {"page": "/blog", "clicks": 450},
                    {"page": "/products", "clicks": 320},
                    {"page": "/contact", "clicks": 210}
                ]
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ú† Ú©Ù†Ø³ÙˆÙ„: {e}")
            raise

    def get_analytics_data(self, view_id: str, start_date: str, end_date: str) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú¯ÙˆÚ¯Ù„ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³"""
        try:
            # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª ÙˆØ§Ù‚Ø¹ÛŒ
            params = {
                "viewId": view_id,
                "dateRanges": [{"startDate": start_date, "endDate": end_date}],
                "metrics": [
                    {"expression": "ga:sessions"},
                    {"expression": "ga:users"},
                    {"expression": "ga:pageviews"}
                ],
                "dimensions": [{"name": "ga:pagePath"}]
            }
            
            # Ø¯Ø± ÛŒÚ© Ø³ÛŒØ³ØªÙ… ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø§ÛŒÙ†Ø¬Ø§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ API Ú¯ÙˆÚ¯Ù„ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            return {
                "sessions": 4500,
                "users": 3200,
                "pageviews": 12000,
                "avg_session_duration": "00:02:45",
                "bounce_rate": 0.42,
                "top_pages": [
                    {"page": "/blog/seo-guide", "views": 1200},
                    {"page": "/products/seo-tool", "views": 850},
                    {"page": "/contact", "views": 620}
                ]
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù†Ø§Ù„ÛŒØªÛŒÚ©Ø³: {e}")
            raise

# ##################################################
# ## ------ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ ------ ##
# ##################################################

class SEOAssistantBot:
    """Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø¦ÙˆÚ©Ø§Ø± Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ± Ùˆ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    
    def __init__(self, config: Config):
        # ØªØ£ÛŒÛŒØ¯ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¶Ø±ÙˆØ±ÛŒ
        if not config.BOT_TOKEN:
            raise ValueError("ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯")
        if not config.ENCRYPTION_KEY:
            raise ValueError("Ú©Ù„ÛŒØ¯ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯")
            
        self.config = config
        self._init_managers()
        self._init_telegram()
        self._setup_metrics()
        self._load_user_data()
        
        logger.info("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ø±Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")

    def _init_managers(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ù…Ø¯ÛŒØ±Ø§Ù† Ø³Ø±ÙˆÛŒØ³"""
        self.model_manager = ModelManager(self.config)
        self.security_manager = SecurityManager(self.config.ENCRYPTION_KEY)
        self.payment_manager = PaymentManager(self.config)
        self.analytics_manager = AnalyticsManager(self.config)
        self.google_integration = GoogleIntegration(self.config.GOOGLE_API_KEY) if self.config.GOOGLE_API_KEY else None
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ML
        if not self.model_manager.load_models():
            raise RuntimeError("Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†")

    def _init_telegram(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ØªÙ„Ú¯Ø±Ø§Ù…"""
        self.updater = Updater(
            self.config.BOT_TOKEN,
            use_context=True,
            request_kwargs={
                'read_timeout': self.config.REQUEST_TIMEOUT,
                'connect_timeout': self.config.REQUEST_TIMEOUT
            }
        )
        self.dp = self.updater.dispatcher
        self.job_queue = self.updater.job_queue
        
        # ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø®Ø·Ø§
        self.dp.add_error_handler(self._handle_error)
        
        # ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª
        self._setup_command_handlers()
        self._setup_message_handlers()
        self._setup_callback_handlers()

    def _setup_metrics(self):
        """ØªÙ†Ø¸ÛŒÙ… Ø³ÛŒØ³ØªÙ… Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯"""
        if os.getenv('ENABLE_METRICS', 'false').lower() == 'true':
            start_http_server(8000)
            logger.info("Ø³ÛŒØ³ØªÙ… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 8000 Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")

    def _load_user_data(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø² Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        try:
            data_dir = Path(self.config.USER_DATA_DIR)
            for user_file in data_dir.glob('*.json'):
                try:
                    user_id = int(user_file.stem)
                    with open(user_file, 'r', encoding='utf-8') as f:
                        encrypted_data = json.load(f)
                        decrypted_data = json.loads(self.security_manager.decrypt_data(encrypted_data))
                        self.user_profiles[user_id] = UserProfile(user_id, self.config, self.security_manager)
                        self.user_profiles[user_id].data = decrypted_data
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_file.stem}: {e}")
            
            logger.info(f"Ø¯Ø§Ø¯Ù‡ {len(self.user_profiles)} Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            ACTIVE_USERS_GAUGE.set(len(self.user_profiles))
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {e}")
            raise

    def _setup_command_handlers(self):
        """ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª"""
        handlers = [
            CommandHandler('start', self._handle_start),
            CommandHandler('help', self._handle_help),
            CommandHandler('menu', self._handle_menu),
            CommandHandler('keywords', self._handle_keywords),
            CommandHandler('content', self._handle_content),
            CommandHandler('optimize', self._handle_optimize),
            CommandHandler('analyze', self._handle_analyze),
            CommandHandler('compare', self._handle_compare),
            CommandHandler('competitor', self._handle_competitor),
            CommandHandler('save', self._handle_save),
            CommandHandler('list', self._handle_list),
            CommandHandler('get', self._handle_get),
            CommandHandler('profile', self._handle_profile),
            CommandHandler('subscribe', self._handle_subscribe),
            CommandHandler('upgrade', self._handle_upgrade),
            CommandHandler('language', self._handle_language),
            CommandHandler('report', self._handle_report),
            CommandHandler('stats', self._handle_stats),
            CommandHandler('backup', self._handle_backup)
        ]
        
        for handler in handlers:
            self.dp.add_handler(handler)

    def _setup_message_handlers(self):
        """ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ"""
        self.dp.add_handler(MessageHandler(Filters.text & ~Filters.command, self._handle_text_message))
        self.dp.add_handler(MessageHandler(Filters.document, self._handle_document))

    def _setup_callback_handlers(self):
        """ØªÙ†Ø¸ÛŒÙ… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ callback Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§"""
        self.dp.add_handler(CallbackQueryHandler(self._handle_callback))

    def _handle_error(self, update: Update, context: CallbackContext):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ù…ØªÙ…Ø±Ú©Ø² Ø®Ø·Ø§Ù‡Ø§"""
        error = context.error
        user_id = update.effective_user.id if update.effective_user else None
        
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø§Ø±Ø¨Ø± {user_id}: {error}", exc_info=error)
        ERROR_COUNTER.labels(endpoint=update.message.text.split()[0] if update.message else 'unknown').inc()
        
        try:
            if user_id:
                context.bot.send_message(
                    chat_id=user_id,
                    text="âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
                )
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±: {e}")

    # ##################################################
    # ## -------- Ø¯Ø³ØªÙˆØ±Ø§Øª Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª -------- ##
    # ##################################################

    def _handle_start(self, update: Update, context: CallbackContext):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø³ØªÙˆØ± /start"""
        REQUEST_COUNTER.labels(endpoint='start').inc()
        user = update.effective_user
        user_profile = self._get_user_profile(user.id)
        
        if not self._check_rate_limit(user.id, 'start'):
            update.message.reply_text("â³ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.")
            return
        
        welcome_msg = self._generate_welcome_message(user)
        keyboard = self._generate_main_keyboard()
        
        update.message.reply_text(
            welcome_msg,
            reply_markup=InlineKeyboardMarkup(keyboard),
            parse_mode="Markdown"
        )

    def _handle_help(self, update: Update, context: CallbackContext):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø³ØªÙˆØ± /help"""
        REQUEST_COUNTER.labels(endpoint='help').inc()
        user_profile = self._get_user_profile(update.effective_user.id)
        
        if not self._check_rate_limit(update.effective_user.id, 'help'):
            update.message.reply_text("â³ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.")
            return
        
        help_text = self._generate_help_text(user_profile)
        update.message.reply_text(help_text, parse_mode="Markdown")

    def _handle_keywords(self, update: Update, context: CallbackContext):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø³ØªÙˆØ± /keywords"""
        REQUEST_COUNTER.labels(endpoint='keywords').inc()
        user = update.effective_user
        user_profile = self._get_user_profile(user.id)
        
        if not self._check_rate_limit(user.id, 'keywords'):
            update.message.reply_text("â³ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§ Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ Ø­Ø¯ Ù…Ø¬Ø§Ø² Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.")
            return
        
        if not context.args:
            update.message.reply_text("Ù„Ø·ÙØ§Ù‹ Ù…ÙˆØ¶ÙˆØ¹ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.\nÙ…Ø«Ø§Ù„: /keywords Ø¢Ù…ÙˆØ²Ø´ Ø³Ø¦Ùˆ")
            return
        
        query = " ".join(context.args)
        if len(query) > 200:
            update.message.reply_text("âš ï¸ Ø·ÙˆÙ„ Ù…ÙˆØ¶ÙˆØ¹ Ù†Ø¨Ø§ÛŒØ¯ Ø§Ø² 200 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø¨ÛŒØ´ØªØ± Ø¨Ø§Ø´Ø¯.")
            return
        
        try:
            update.message.reply_text("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ...")
            
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
            keywords = self._generate_keyword_suggestions(query)
            
            response = (
                f"ğŸ” *Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ '{query}':*\n\n" +
                "\n".join(f"ğŸ”¹ {kw}" for kw in keywords) +
                "\n\nğŸ’¡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ø§ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯."
            )
            
            update.message.reply_text(response, parse_mode="Markdown")
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
            user_profile.save_content({
                "type": "keyword_research",
                "title": f"Ù¾Ú˜ÙˆÙ‡Ø´ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ {query}",
                "content": "\n".join(keywords),
                "tags": [query]
            })
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {e}")
            update.message.reply_text("âš ï¸ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

    # ##################################################
    # ## -------- Ù…ØªØ¯Ù‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ -------- ##
    # ##################################################

    def _generate_keyword_suggestions(self, query: str) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ML"""
        try:
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
            result = self.model_manager.models["keyword"](
                f"Generate 15 SEO keywords for: {query}",
                max_length=100,
                num_return_sequences=1,
                temperature=0.7,
                top_k=50
            )
            
            keywords = result[0]["generated_text"].split(",")
            cleaned_keywords = [kw.strip() for kw in keywords if kw.strip()]
            
            # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ
            unique_keywords = list(dict.fromkeys(cleaned_keywords))
            return unique_keywords[:self.config.KEYWORD_SUGGESTIONS]
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {e}")
            # Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
            return [
                f"{query} Ø¢Ù…ÙˆØ²Ø´",
                f"Ø¢Ù…ÙˆØ²Ø´ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ {query}",
                f"Ø¨Ù‡ØªØ±ÛŒÙ† Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ {query}",
                f"{query} 2023",
                f"Ø¢Ù…ÙˆØ²Ø´ Ø±Ø§ÛŒÚ¯Ø§Ù† {query}",
                f"Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ {query}",
                f"{query} Ù¾ÛŒØ´Ø±ÙØªÙ‡",
                f"Ù…ØªØ¯Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ {query}",
                f"Ø¢Ù…ÙˆØ²Ø´ ØªØµÙˆÛŒØ±ÛŒ {query}",
                f"{query} Ø¨Ø±Ø§ÛŒ Ù…Ø¨ØªØ¯ÛŒØ§Ù†"
            ]

    def _generate_welcome_message(self, user: User) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯ÙˆÛŒÛŒ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡"""
        plan = self.config.SUBSCRIPTION_PLANS.get(
            self._get_user_profile(user.id).data["subscription"]["plan"], 
            self.config.SUBSCRIPTION_PLANS["free"]
        )
        
        return (
            f"âœ¨ Ø³Ù„Ø§Ù… {user.first_name} Ø¹Ø²ÛŒØ²!\n"
            f"Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø³Ø¦ÙˆÚ©Ø§Ø± Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\n\n"
            f"ğŸ”¹ Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø·Ø±Ø­ *{plan.name}* Ù‡Ø³ØªÛŒØ¯\n"
            f"ğŸ”¸ Ø§Ù…Ú©Ø§Ù†Ø§Øª ÙØ¹Ù„ÛŒ Ø´Ù…Ø§:\n"
            + "\n".join(f"â€¢ {feature}" for feature in plan.features) +
            "\n\nØ¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ù…Ù†ÙˆÛŒ Ø²ÛŒØ± Ø§Ù‚Ø¯Ø§Ù… Ú©Ù†ÛŒØ¯:"
        )

    def _generate_main_keyboard(self) -> List[List[InlineKeyboardButton]]:
        """ØªÙˆÙ„ÛŒØ¯ Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø§ØµÙ„ÛŒ Ø¨Ø§ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ÛŒØ´Ù‡â€ŒØ§ÛŒ"""
        return [
            [InlineKeyboardButton("ğŸ” Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ", callback_data='keywords')],
            [InlineKeyboardButton("âœï¸ ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø³Ø¦Ùˆ Ø´Ø¯Ù‡", callback_data='content')],
            [InlineKeyboardButton("âš¡ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†", callback_data='optimize')],
            [InlineKeyboardButton("ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ", callback_data='analyze')],
            [InlineKeyboardButton("ğŸ”„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ù…ØªÙ†", callback_data='compare')],
            [InlineKeyboardButton("ğŸ† ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§", callback_data='competitor')],
            [InlineKeyboardButton("ğŸ“š Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹", callback_data='help')],
            [InlineKeyboardButton("ğŸ‘¤ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±ÛŒ", callback_data='profile')]
        ]

    def _generate_help_text(self, user_profile: UserProfile) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹"""
        plan = self.config.SUBSCRIPTION_PLANS.get(
            user_profile.data["subscription"]["plan"], 
            self.config.SUBSCRIPTION_PLANS["free"]
        )
        
        return f"""
ğŸ“š *Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¬Ø§Ù…Ø¹ Ø±Ø¨Ø§Øª Ø³Ø¦ÙˆÚ©Ø§Ø±*

ğŸ” *Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ*
/keywords [Ù…ÙˆØ¶ÙˆØ¹]
- Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·
- Ù…Ø«Ø§Ù„: `/keywords Ø¢Ù…ÙˆØ²Ø´ Ø³Ø¦Ùˆ`

âœï¸ *ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§*
/content [Ù†ÙˆØ¹] [Ù…ÙˆØ¶ÙˆØ¹]
- ØªÙˆÙ„ÛŒØ¯ Ù…Ø­ØªÙˆØ§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡
- Ø§Ù†ÙˆØ§Ø¹: Ù…Ù‚Ø§Ù„Ù‡ØŒ Ù…Ø­ØµÙˆÙ„ØŒ ØµÙØ­Ù‡ ÙØ±ÙˆØ¯ØŒ Ù¾Ø³Øª ÙˆØ¨Ù„Ø§Ú¯
- Ù…Ø«Ø§Ù„: `/content article Ø¢Ù…ÙˆØ²Ø´ Ø³Ø¦Ùˆ`

âš¡ *Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØªÙ†*
/optimize [Ù…ØªÙ†]
- Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø§Ø®ØªØ§Ø± Ùˆ Ø³Ø¦Ùˆ Ù…ØªÙ†
- Ù…Ø«Ø§Ù„: `/optimize Ø§ÛŒÙ† ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ù…ØªÙ† Ø§Ø³Øª...`

ğŸ“Š *ØªØ­Ù„ÛŒÙ„ Ø³Ø¦Ùˆ*
/analyze [Ù…ØªÙ† ÛŒØ§ URL]
- ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø§Ø² Ù†Ø¸Ø± Ø³Ø¦Ùˆ
- Ù…Ø«Ø§Ù„: `/analyze https://example.com`

ğŸ”„ *Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ù…ØªÙ†*
/compare [Ù…ØªÙ†1]\n[Ù…ØªÙ†2]
- Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´Ø¨Ø§Ù‡Øª Ùˆ Ú©ÛŒÙÛŒØª Ø¯Ùˆ Ù…ØªÙ†
- Ù…Ø«Ø§Ù„: `/compare Ù…ØªÙ† Ø§ÙˆÙ„...\nÙ…ØªÙ† Ø¯ÙˆÙ…...`

ğŸ† *ØªØ­Ù„ÛŒÙ„ Ø±Ù‚Ø¨Ø§*
/competitor [URL Ø±Ù‚ÛŒØ¨] [Ù…ØªÙ† Ø´Ù…Ø§]
- Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø´Ù…Ø§ Ø¨Ø§ Ø±Ù‚ÛŒØ¨
- Ù…Ø«Ø§Ù„: `/competitor https://example.com Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ù† Ø§Ø³Øª...`

ğŸ’ *Ø·Ø±Ø­ Ø§Ø´ØªØ±Ø§Ú© Ø´Ù…Ø§*: {plan.name}
ğŸ“Œ *Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø±ÙˆØ²Ø§Ù†Ù‡*: {plan.rate_limit}
"""

    def _check_rate_limit(self, user_id: int, endpoint: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø§Ø±Ø¨Ø±"""
        user_profile = self._get_user_profile(user_id)
        can_request, message = user_profile.can_make_request(endpoint)
        
        if not can_request:
            REQUEST_COUNTER.labels(endpoint=endpoint).inc()
            return False
            
        return True

    def _get_user_profile(self, user_id: int) -> UserProfile:
        """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯"""
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = UserProfile(user_id, self.config, self.security_manager)
            ACTIVE_USERS_GAUGE.inc()
            logger.info(f"Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
            
        return self.user_profiles[user_id]

    # ##################################################
    # ## -------- Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ -------- ##
    # ##################################################

    def _schedule_jobs(self):
        """Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡"""
        # Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡
        self.job_queue.run_daily(
            self._daily_backup_task,
            time=datetime.strptime("03:00", "%H:%M").time(),
            days=(0, 1, 2, 3, 4, 5, 6),
            name="daily_backup"
        )
        
        # Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ
        self.job_queue.run_daily(
            self._weekly_report_task,
            time=datetime.strptime("10:00", "%H:%M").time(),
            days=(6,),  # Ø´Ù†Ø¨Ù‡
            name="weekly_report"
        )
        
        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ML Ù‡Ø± 24 Ø³Ø§Ø¹Øª
        self.job_queue.run_repeating(
            self._refresh_models_task,
            interval=86400,
            first=0,
            name="refresh_models"
        )
        
        logger.info("Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯Ù†Ø¯")

    def _daily_backup_task(self, context: CallbackContext):
        """ÙˆØ¸ÛŒÙÙ‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        try:
            backup_name = f"backup_{datetime.now().strftime('%Y%m%d')}"
            all_data = {
                str(user_id): profile.data 
                for user_id, profile in self.user_profiles.items()
            }
            
            if self.backup_manager.create_backup(all_data, backup_name):
                logger.info(f"Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø§ Ù†Ø§Ù… {backup_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
            else:
                logger.warning("Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ¸ÛŒÙÙ‡ Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡: {e}")

    def _weekly_report_task(self, context: CallbackContext):
        """ÙˆØ¸ÛŒÙÙ‡ Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ"""
        try:
            total_users = len(self.user_profiles)
            active_users = sum(1 for profile in self.user_profiles.values() 
                             if profile.data["usage"]["daily_requests"] > 0)
            
            report = (
                "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø±Ø¨Ø§Øª Ø³Ø¦ÙˆÚ©Ø§Ø±\n\n"
                f"ğŸ‘¥ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ú©Ù„: {total_users}\n"
                f"ğŸ”„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÙØ¹Ø§Ù„ Ø§ÛŒÙ† Ù‡ÙØªÙ‡: {active_users}\n"
                f"ğŸ“Œ Ù…Ø¬Ù…ÙˆØ¹ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§: {sum(p.data['usage']['total_requests'] for p in self.user_profiles.values())}\n\n"
                "âœ… Ø³ÛŒØ³ØªÙ… Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯"
            )
            
            # Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†â€ŒÙ‡Ø§ (Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ ÙÙ‚Ø· Ù„Ø§Ú¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…)
            logger.info(report)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ¸ÛŒÙÙ‡ Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ: {e}")

    def _refresh_models_task(self, context: CallbackContext):
        """ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ML"""
        try:
            logger.info("Ø´Ø±ÙˆØ¹ ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†...")
            self.model_manager.load_models()
            logger.info("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù†Ø¯")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ§Ø²Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {e}")

    # ##################################################
    # ## -------- Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Ø§ØµÙ„ÛŒ Ø±Ø¨Ø§Øª -------- ##
    # ##################################################

    def run(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§"""
        try:
            # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
            if os.getenv('ENABLE_METRICS', 'false').lower() == 'true':
                start_http_server(8000)
                logger.info("Ø³ÛŒØ³ØªÙ… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª 8000 Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
            
            # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡
            self._schedule_jobs()
            
            # Ø´Ø±ÙˆØ¹ Ø±Ø¨Ø§Øª
            self.updater.start_polling()
            logger.info("âœ… Ø±Ø¨Ø§Øª Ø³Ø¦ÙˆÚ©Ø§Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯")
            self.updater.idle()
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª: {e}")
            raise
        finally:
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù‚Ø¨Ù„ Ø§Ø² Ø®Ø±ÙˆØ¬
            for user_id in self.user_profiles:
                self._save_user_data(user_id)
            logger.info("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯")

    def _save_user_data(self, user_id: int):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§"""
        try:
            if user_id not in self.user_profiles:
                return
                
            user_dir = Path(self.config.USER_DATA_DIR)
            user_dir.mkdir(exist_ok=True, mode=0o700)
            
            user_file = user_dir / f"{user_id}.json"
            encrypted_data = self.security_manager.encrypt_data(
                json.dumps(self.user_profiles[user_id].data, ensure_ascii=False)
            
            with open(user_file, 'w', encoding='utf-8') as f:
                json.dump(encrypted_data, f, ensure_ascii=False)
            
            logger.debug(f"Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id}: {e}")

if __name__ == '__main__':
    try:
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
        config = Config()
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¶Ø±ÙˆØ±ÛŒ
        if not config.BOT_TOKEN:
            raise ValueError("ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ BOT_TOKEN Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
            
        if not config.ENCRYPTION_KEY:
            raise ValueError("Ú©Ù„ÛŒØ¯ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø¨Ø§ÛŒØ¯ ØªÙ†Ø¸ÛŒÙ… Ø´ÙˆØ¯. Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ ENCRYPTION_KEY Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª
        bot = SEOAssistantBot(config)
        bot.run()
    except Exception as e:
        logger.critical(f"Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª: {e}")
        raise
